\documentclass[a4paper,12pt,twocolumn]{article}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}

% Set top and bottom to 1in too.
\usepackage[margin=1in]{geometry}

\usepackage{titling}
\usepackage{nomencl}
\usepackage{siunitx}
\usepackage[style=ieee,backend=bibtex]{biblatex}
\usepackage[font={small}]{caption}

\usepackage{graphicx}
\usepackage{color}
\usepackage[table]{xcolor}

\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{fancyhdr}
\usepackage{float}

\usepackage{varioref}
\usepackage{xspace}
\usepackage{textcomp}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=nonfrench,factor=1100,stretch=10,shrink=10]{microtype}
% activate={true,nocompatibility} - activate protrusion and expansion final -
% enable microtype; use "draft" to disable tracking=true, kerning=true,
% spacing=true - activate these techniques factor=1100 - add 10% to the
% protrusion amount (default is 1000) stretch=10, shrink=10 - reduce
% stretchability/shrinkability (default is 20/20) Reduce tracking around small
% caps to 40%
\SetTracking{encoding={*}, shape=sc}{40}

% Document info.
\author{Z0966990}
\title{Numerical Methods in \textsc{Matlab}\textsuperscript{\textregistered}}
\date{\today}

% Path to images.
\graphicspath{{img/}}

% Setup bibiliography.
\renewcommand{\bibfont}{\footnotesize}
\addbibresource{numerical_methods.bib}

% Setup bibiliography.

% Header and footer.
\pagestyle{fancy}
\fancyhf{}
\lhead{\thetitle}
\rhead{\theauthor}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Macros.
\newcommand{\textsc{fdm}}{\textsc{fdm}\xspace}
\newcommand{\textsc{ode}}{\textsc{ode}\xspace}
\newcommand{\textsc{ode}s}{\textsc{ode}s\xspace}
\newcommand{\textsc{pde}}{\textsc{pde}\xspace}
\newcommand{\textsc{pde}s}{\textsc{pde}s\xspace}
\begin{document}
    
% Title page.
\begin{titlepage}
    \centering
    \vspace*{\fill}
    \includegraphics[width=0.5\textwidth]{Durham.png}\\
    \vspace*{\fill}
    \LARGE\thetitle\\
    \large\theauthor\\
    \large L2 Engineering Mathematics\\
    \large\thedate\\
    \vspace*{\fill}
\end{titlepage}

% Main matter.

\section{Taylor Series Method}

The $p$\textsuperscript{th} order Taylor's series method for \textsc{ode}s finds
numerical approximations to equations of the form $y'(t) = f(t,y)$. In $n$ steps
it approximates the solution $y_n$ at some time $T$ given an initial condition:
{\footnotesize
\begin{equation} \label{eq:taylor-method}
    \begin{aligned}
        t_0 &= 0 &
        y_0 &= y(0) \\
        t_{i+1} &= t_i + h &
        y_{i+1} &= y_i + \sum_{k=1}^{p}\frac{h^k}{k!}f^{(k-1)}(t_i,y_i) \\
        t_n &= T &
        y_n &\approx y(T) 
    \end{aligned}
\end{equation}
}where $h = T/n$ and is the step-size.

The use of successive approximations results in an error composed of the
accumulation error and truncation error at each step. At time $T$, this is
the final global error:
{\footnotesize
\begin{equation} \label{eq:error}
        \epsilon_n = |y_n - y(T)| = O(h^p) = O(n^{-p})
\end{equation}

}A \textsc{Matlab} implementation of \eqref{eq:taylor-method} with order 4 was
applied to three \textsc{ode}s of the form $y'(t) = f(t,y)$. These were defined 
as follows:
{\footnotesize
\begin{align}
    \tag{a}\label{ode:a}
    y'(t) &= \sin(t) & y(0) &= 0 & 0 &\leq t \leq \pi  \\
    \tag{b}\label{ode:b}
    y'(t) &= 5y(t)   & y(0) &= 1 & 0 &\leq t \leq 0.1 \\
    \tag{c}\label{ode:c}
    y'(t) &= 2       & y(0) &= 0 & 0 &\leq t \leq 1
\end{align}

}\subsection{Results}

The results of the fourth order Taylor series method were compared to the 
results of Taylor's second and Euler's method---which is a first order 
Taylor's series method. Table~\ref{table:ode} lists $y_n$ for different numbers 
of iterations $n$.

\begin{table}[h]
    \centering
    \footnotesize
    \caption{\textsc{Ode} Verification Simulations}
    \label{table:ode}
    \begin{threeparttable}
        \begin{tabular}{
            @{}
            l
            S[table-format=2]
            S[table-format=1.2]
            S[table-format=1.2]
            S[table-format=1.2]
            @{}
        }
            \toprule
            & $n$
            & {\bf Euler\tnote{$\dagger$}}
            & {\bf Taylor 2\textsuperscript{nd}\tnote{$\dagger$}}
            & {\bf Taylor 4\textsuperscript{th}\tnote{$\dagger$}} \\
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{ode}~\eqref{ode:a}\\at $t=\mathrm{\pi}$}}}
            & 10 & 1.99 & 2.03 & 2.00 \\
            & 20 & 2.00 & 2.01 & 2.00 \\
            & 40 & 2.00 & 2.00 & 2.00 \\
            & 80 & 2.00 & 2.00 & 2.00 \\
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{ode}~\eqref{ode:b}\\at $t=0.1$}}}
            & 10 & 1.63 & 1.65 & 1.65 \\
            & 20 & 1.64 & 1.65 & 1.65 \\
            & 40 & 1.64 & 1.65 & 1.65 \\
            & 80 & 1.65 & 1.65 & 1.65 \\
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{ode}~\eqref{ode:c}\\at $t=1$}}}
            & 10 & 2.00 & 2.00 & 2.00 \\
            & 20 & 2.00 & 2.00 & 2.00 \\
            & 40 & 2.00 & 2.00 & 2.00 \\
            & 80 & 2.00 & 2.00 & 2.00 \\
            \bottomrule
        \end{tabular}
        \begin{tablenotes}
            \item[$\dagger$] Accurate to 3 significant figures.
        \end{tablenotes}
    \end{threeparttable}
\end{table}

\textsc{Ode}~\eqref{ode:c} had no non-zero derivatives in $f(t,y)$, so Euler's 
method contained sufficiently many terms to find $y_n$ when $T=1$---higher order
methods behaved as Euler's method. For \textsc{ode}s \eqref{ode:b} and 
\eqref{ode:c}, many more iterations were required for the lower order methods 
to converge on a value for $y_n$ as the higher order coefficients were larger.

The exact errors of the results in Table~\ref{table:ode} are detailed in 
Table~\ref{table:err}, in which \textsc{ode}s \eqref{ode:a} and \eqref{ode:b} 
demonstrate how increasing the number of iterations reduces the final global 
error, as suggested in \eqref{eq:error}. Equation~\eqref{eq:error} also 
suggests increasing the order of the Taylor's series method reduces the final 
global error. Particularly for \textsc{ode}~\eqref{ode:b}, doubling the order 
of the method halved the magnitude of the error.

\begin{table}[h]
    \centering
    \footnotesize
    \caption{\textsc{Ode} Errors}
    \label{table:err}
    \begin{threeparttable}
        \begin{tabular}{
            @{}
            l
            S[table-format=2]
            S[table-format=1.2e+2]
            S[table-format=1.2e+2]
            S[table-format=1.2e+2]
            @{}
        }
            \toprule
            & {$n$}
            & {\bf\shortstack{Euler\\Error\tnote{$\dagger$}}}
            & {\bf\shortstack{Taylor 2\textsuperscript{nd}\\
                Error\tnote{$\dagger$}}}
            & {\bf\shortstack{Taylor 4\textsuperscript{th}\\
                Error\tnote{$\dagger$}}}\\
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{Ode}~\eqref{ode:a}\\at $t=\mathrm{\pi}$}}}
            & 10 & 1.65e-02 & 3.29e-02 & 1.62e-04 \\
            & 20 & 4.11e-03 & 8.22e-03 & 1.01e-05 \\
            & 40 & 1.03e-03 & 2.06e-03 & 6.34e-07 \\
            & 80 & 2.57e-04 & 5.14e-04 & 3.96e-08 \\
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{Ode}~\eqref{ode:b}\\at $t=0.1$}}}
            & 10 & 1.98e-02 & 3.31e-04 & 4.12e-08 \\ 
            & 20 & 1.01e-02 & 8.43e-05 & 2.63e-09 \\ 
            & 40 & 5.10e-03 & 2.13e-05 & 1.66e-10 \\ 
            & 80 & 2.56e-03 & 5.34e-06 & 1.04e-11 \\ 
            \midrule
            \multirow{4}{*}{\rotatebox[origin=c]{90}{
                \shortstack{\textsc{Ode}~\eqref{ode:c}\\at $t=1$}}}
            & 10 & 2.22e-16 & 2.22e-16 & 2.22e-16 \\ 
            & 20 & 4.44e-16 & 4.44e-16 & 4.44e-16 \\ 
            & 40 & 8.88e-16 & 8.88e-16 & 8.88e-16 \\ 
            & 80 & 3.11e-15 & 3.11e-15 & 3.11e-15 \\ 
            \bottomrule
        \end{tabular}
        \begin{tablenotes}
            \item[$\dagger$] Accurate to 3 significant figures.
        \end{tablenotes}
    \end{threeparttable}
\end{table}



For \textsc{ode}~\eqref{ode:c}, higher order methods behave as Euler's method, 
so the order of the method has no effect on accuracy. Contrary to 
\eqref{eq:error} the error increased with the number of iterations. This can be 
explained by the round off error in $h$. When $n=10$, binary64 format cannot 
encode every bit of the recurring binary fraction
\mbox{$h=0.0\dot{0}01\dot{1}_2$}. As the number of iterations $n$ increase, 
more round off error accumulates.

\section{Finite Difference\\Method}

The convection--diffusion--reaction equation can be used to describe how mass 
concentration $u$ varies in space $\mathbf{x}$ with time $t$. The parabolic 
equation includes convection $\mathbf{v}\cdot\nabla u$, wherein the mass has a 
net velocity $\mathbf{v}$; diffusion $c^2\nabla^2u$, where random motion 
disperses mass over time; and reaction $du$, a sink or source of mass---present 
when chemical reactions are taking place.

The equation can also be applied to heat transfer, where $u$ represents heat.

In \textsc{1d}, the convection--diffusion--reaction equation is defined as 
follows:
{\footnotesize
    \begin{multline} \label{eq:pde}
            \forall x,t \in (a, b) \times (0, T] \\
            u_t(x,t) = c^2u_{xx}(x,t) + vu_x(x,t) + du(x,t)
    \end{multline}
}with homogenous Dirichlet boundary conditions and initial condition 
\mbox{$u(x,0)=f(x)$} applied.

A \textsc{fdm} schema was devised to numerically solve \eqref{eq:pde}, second order in 
space with interval $h$, first order in time with time-step $k$, and 
implemented in \textsc{Matlab} as follows:
{\footnotesize
    \begin{multline} \label{eq:schema}
        u^i_{j+1} = u^i_j + dku^i_j + \frac{vk}{2h}(u^{i+1}_j - u^{i-1}_j) \\
            + \frac{c^2k}{h^2}(u^{i+1}_j - 2u^i_j + u^{i-1}_j)
    \end{multline}

}Errors in \textsc{fdm} schema can grow or be damped out at each time-step, leading to a
stable and accurate, or unstable solutions. Von Neumann stability analysis 
assumes these errors are amplified by a constant
factor~\cite{charney1950numerical}. An expression for amplification factor is 
determined by expressing the errors as a Fourier series in space. Stability 
necessitates the amplification factor is less than unity for all frequencies 
resolvable in the grid.

Applying von Neumann stability analysis to \eqref{eq:schema} yielded the 
following stability criterion, and expression for the amplification factor:
{\footnotesize
    \begin{gather}
        \label{eq:stability}
        G = \left| 1 + R - 2S \pm \sqrt{(2S)^2 + C^2} \right|
            \leq 1 + \epsilon k \\
        \nonumber
        \begin{aligned}
            R &= dk & C &= \frac{vk}{h} & S &= \frac{c^2k}{h^2}
        \end{aligned}
    \end{gather}
}where $R$, $C$ and $S$ are dimensionless quantities: the reaction, Courant and 
diffusion numbers. $\epsilon$ is a constant assumed to be smaller than 
\num{800e-3}.

The model was tested on the following:
{\footnotesize
    \begin{align*}
        c &= 1    & a &= 0   & m,n  =&\;\{10,100,200,400,800\} \\
        v &= 0.5  & b &= 1   &       &\;\times \{4,16,32\} \\
        d &= 0.02 & T &= 0.2 & f(x) =&\;4x - 4x^2
    \end{align*}

}With these coefficients fixed, the amplification factor in \eqref{eq:stability}
varies as follows:
{\footnotesize
    \begin{equation} \label{eq:gain}
        G = O(k/h^2) = O(n^2/m)
    \end{equation}

}\subsection{Results}

Table~\ref{table:pde} lists the value of \eqref{eq:pde} at the midpoint of the 
interval at time $T$, for each $n$ and $m$.

\begin{table}[h]
    \centering
    \footnotesize
    \caption{\textsc{Pde} Verification Simulations}
    \label{table:pde}
    \begin{threeparttable}
        \begin{tabular}{
            @{\hspace{1em}}
            S[table-format=2]
            S[table-format=3]
            S[table-format=+2.2e2]
            S[table-format=2.2]
            @{\hspace{1em}}
        }
            \toprule
            {$n$} & {$m$} & {$u(0.5,0.2)$\tnote{$\dagger$}} & 
                {$G$\tnote{$\dagger$}}\\
            \cmidrule(rl){1-3}\cmidrule(rl){4-4}
             4 &  10 &    0.129   &  1.00 \\\rowcolor{red!20}
            16 &  10 &   -1.13e7  & 19.5  \\\rowcolor{red!20}
            32 &  10 &  -87.3     & 80.9  \\
             4 & 100 &    0.155   &  1.00 \\\rowcolor{red!20}
            16 & 100 &    0.139   &  1.05 \\\rowcolor{red!20}
            32 & 100 &   -1.53e80 &  7.19 \\
             4 & 200 &    0.156   &  1.00 \\
            16 & 200 &    0.142   &  1.00 \\\rowcolor{red!20}
            32 & 200 &   -4.66e92 &  3.1  \\
             4 & 400 &    0.157   &  1.00 \\
            16 & 400 &    0.143   &  1.00 \\\rowcolor{red!20}
            32 & 400 &   -1.30e2  &  1.05 \\
             4 & 800 &    0.157   &  1.00 \\
            16 & 800 &    0.143   &  1.00 \\
            32 & 800 &    0.142   &  1.00 \\
            \bottomrule
        \end{tabular}
        \begin{tablenotes}
            \item\colorbox{red!20}{Unstable: unable to satisfy
                \eqref{eq:stability}.}
            \item[$\dagger$] Accurate to 3 significant figures.
        \end{tablenotes}
    \end{threeparttable}
\end{table}

The highlighted simulations with a gain greater than unity did not appear to
converge on similar values to those determined stable by \eqref{eq:stability}.
This occurred when there were too many intervals in space for a given number of
time-steps, as predicted by \eqref{eq:gain}.

% References.
\printbibliography

\end{document}